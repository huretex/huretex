{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21cea9cf",
   "metadata": {},
   "source": [
    "## HuReTEx DLS 0.01 (2025.11.05) - Deep Learning System with the MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558be1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from interface import implements\n",
    "import importlib\n",
    "import ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ead8d033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ipynb.fs.full.HuReTEx_DLSI_0_01' (/var/srv/183110/Moje/Nauka/HuReTEx/HuRuTEx_github/HuReTEx_DLSI_0_01.ipynb)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipynb.fs.full.HuReTEx_DLSI_0_01 import DeepLearningSystemInterface\n",
    "importlib.reload(ipynb.fs.full.HuReTEx_DLSI_0_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21bd90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalSimpleMNIST(implements(DeepLearningSystemInterface)):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        n_classes = 10\n",
    "\n",
    "        self.n_filters_conv_1 = 4\n",
    "        self.filter_size_conv_1 = 3\n",
    "        self.n_filters_conv_2 = 4\n",
    "        self.filter_size_conv_2 = 3\n",
    "        self.n_neurons_dense_1 = 256\n",
    "        self.n_neurons_dense_2 = n_classes\n",
    "\n",
    "        (x_train_valid, y_train_valid), (x_test, y_test) = mnist.load_data()\n",
    "        x_train, x_valid, y_train, y_valid = train_test_split(x_train_valid, y_train_valid, test_size=0.2, stratify=y_train_valid)\n",
    "\n",
    "        x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], x_train.shape[2], 1))\n",
    "        x_valid = x_valid.reshape((x_valid.shape[0], x_valid.shape[1], x_valid.shape[2], 1))\n",
    "        x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], x_test.shape[2], 1))\n",
    "\n",
    "        x_train = x_train.astype('float32')\n",
    "        x_valid = x_valid.astype('float32')\n",
    "        x_test = x_test.astype('float32')\n",
    "\n",
    "        self.x_train = x_train/255.0\n",
    "        self.x_valid = x_valid/255.0\n",
    "        self.x_test = x_test/255.0\n",
    "\n",
    "        self.y_train = tf.keras.utils.to_categorical(y_train)\n",
    "        self.y_valid = tf.keras.utils.to_categorical(y_valid)\n",
    "        self.y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "        self.model = models.Sequential()\n",
    "        self.model.add(layers.Conv2D(self.n_filters_conv_1, (self.filter_size_conv_1, self.filter_size_conv_1), activation='relu', input_shape=(self.x_train.shape[1], self.x_train.shape[2], self.x_train.shape[3])))\n",
    "        self.model.add(layers.Conv2D(self.n_filters_conv_2, (self.filter_size_conv_2, self.filter_size_conv_2), activation='relu'))\n",
    "        self.model.add(layers.Flatten())\n",
    "        self.model.add(layers.Dense(self.n_neurons_dense_1, activation='relu'))\n",
    "        self.model.add(layers.Dense(self.n_neurons_dense_2, activation='softmax'))\n",
    "        self.model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        self.model.summary()\n",
    "\n",
    "    def train_model(self):\n",
    "\n",
    "        n_epochs = 20\n",
    "        batch_size = 16\n",
    "        \n",
    "        checkpoint = ModelCheckpoint('best_model.keras', \n",
    "            verbose=1, \n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True, \n",
    "            mode='auto'\n",
    "        ) \n",
    "\n",
    "        self.model.fit(self.x_train, self.y_train, epochs=n_epochs, batch_size=batch_size, validation_data=(self.x_valid, self.y_valid), callbacks=[checkpoint])\n",
    "\n",
    "    def calculate_activations(self):\n",
    "\n",
    "        layer_outputs = [layer.output for layer in self.model.layers[:5]]\n",
    "        activation_model = models.Model(inputs=self.model.layers[0].input, outputs=layer_outputs)\n",
    "        self.activations = activation_model.predict(x=self.x_train)\n",
    "\n",
    "    def calculate_artifact_clusters(self):\n",
    "\n",
    "        self.n_clusters_conv_1 = 10\n",
    "        self.n_clusters_conv_2 = 10\n",
    "        self.n_clusters_dense = 10\n",
    "\n",
    "        self.filter_names_conv_1 = list()\n",
    "        self.filter_names_conv_2 = list()\n",
    "\n",
    "        self.artifact_clusters = pd.DataFrame()\n",
    "\n",
    "        for f in range(self.model.layers[0].filters):\n",
    "\n",
    "            print('filter: '+str(f))\n",
    "\n",
    "            activations_f = self.activations[0][:,:,:,f]\n",
    "            activations_f = activations_f.reshape([activations_f.shape[0],activations_f.shape[1]*activations_f.shape[2]])\n",
    "            ac_f = AgglomerativeClustering(n_clusters=self.n_clusters_conv_1, linkage='ward').fit(activations_f)\n",
    "\n",
    "            filter_name = 'l0_f'+str(f)\n",
    "            self.filter_names_conv_1.append(filter_name)\n",
    "\n",
    "            self.artifact_clusters[filter_name] = ac_f.labels_\n",
    "\n",
    "        for f in range(self.model.layers[1].filters):\n",
    "\n",
    "            print('filter: '+str(f))\n",
    "\n",
    "            activations_f = self.activations[1][:,:,:,f]\n",
    "            activations_f = activations_f.reshape([activations_f.shape[0],activations_f.shape[1]*activations_f.shape[2]])\n",
    "            ac_f = AgglomerativeClustering(n_clusters=self.n_clusters_conv_2, linkage='ward').fit(activations_f)\n",
    "\n",
    "            filter_name = 'l1_f'+str(f)\n",
    "            self.filter_names_conv_2.append(filter_name)\n",
    "\n",
    "            self.artifact_clusters[filter_name] = ac_f.labels_\n",
    "\n",
    "        activations_d_1 = self.activations[3]\n",
    "        ac_d = AgglomerativeClustering(n_clusters=self.n_clusters_dense, linkage='ward').fit(activations_d_1)\n",
    "        self.artifact_clusters['l3'] = ac_d.labels_\n",
    "\n",
    "        predictions = self.model.predict(x=self.x_train)\n",
    "        pred = np.argmax(predictions, axis=1)\n",
    "        self.artifact_clusters['p'] = pred\n",
    "\n",
    "    def get_sequential_information_system(self):\n",
    "\n",
    "        self.sis = pd.DataFrame()\n",
    "        self.sis['conv1'] = self.artifact_clusters.astype(str).loc[:,self.filter_names_conv_1].apply('_'.join, axis=1)\n",
    "        self.sis['conv2'] = self.artifact_clusters.astype(str).loc[:,self.filter_names_conv_2].apply('_'.join, axis=1)\n",
    "        self.sis['dense1'] = self.artifact_clusters['l3']\n",
    "        self.sis['output'] = self.artifact_clusters['p']\n",
    "\n",
    "        return self.sis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kp_3_11_10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
