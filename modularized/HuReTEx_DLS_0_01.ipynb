{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21cea9cf",
   "metadata": {},
   "source": [
    "## HuReTEx DLM 0.01 (2025.03.13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "558be1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 21:25:32.665409: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-14 21:25:32.665437: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-14 21:25:32.666285: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-14 21:25:32.670655: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-14 21:25:33.182384: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from interface import implements\n",
    "import importlib\n",
    "import ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ead8d033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ipynb.fs.full.HuReTEx_DLSI_0_01' (/var/srv/183110/Moje/Nauka/HURETEX/HURETEX/HuReTEx_DLSI_0_01.ipynb)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipynb.fs.full.HuReTEx_DLSI_0_01 import DeepLearningSystemInterface\n",
    "importlib.reload(ipynb.fs.full.HuReTEx_DLSI_0_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21bd90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCDLS4MNIST(implements(DeepLearningSystemInterface)):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.n_filters_conv_1 = 4\n",
    "        self.filter_size_conv_1 = 5\n",
    "        self.n_filters_conv_2 = 4\n",
    "        self.filter_size_conv_2 = 5\n",
    "        self.n_neurons_dense_1 = 50\n",
    "        self.n_neurons_dense_2 = 10\n",
    "\n",
    "        (x_train_valid, y_train_valid), (x_test, y_test) = mnist.load_data()\n",
    "        x_train, x_valid, y_train, y_valid = train_test_split(x_train_valid, y_train_valid, test_size=0.2, stratify=y_train_valid)\n",
    "\n",
    "        x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], x_train.shape[2], 1))\n",
    "        x_valid = x_valid.reshape((x_valid.shape[0], x_valid.shape[1], x_valid.shape[2], 1))\n",
    "        x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], x_test.shape[2], 1))\n",
    "\n",
    "        x_train = x_train.astype('float32')\n",
    "        x_valid = x_valid.astype('float32')\n",
    "        x_test = x_test.astype('float32')\n",
    "\n",
    "        self.x_train = x_train/255.0\n",
    "        self.x_valid = x_valid/255.0\n",
    "        self.x_test = x_test/255.0\n",
    "\n",
    "        self.y_train = tf.keras.utils.to_categorical(y_train)\n",
    "        self.y_valid = tf.keras.utils.to_categorical(y_valid)\n",
    "        self.y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "        self.model = models.Sequential()\n",
    "        self.model.add(layers.Conv2D(self.n_filters_conv_1, (self.filter_size_conv_1, self.filter_size_conv_1), activation='relu', input_shape=(x_train.shape[1], x_train.shape[2], x_train.shape[3])))\n",
    "        self.model.add(layers.Conv2D(self.n_filters_conv_2, (self.filter_size_conv_2, self.filter_size_conv_2), activation='relu'))\n",
    "        self.model.add(layers.Flatten())\n",
    "        self.model.add(layers.Dense(self.n_neurons_dense_1, activation='relu'))\n",
    "        self.model.add(layers.Dense(self.n_neurons_dense_2, activation='softmax'))\n",
    "        self.model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    def train_model(self):\n",
    "\n",
    "        n_epochs = 10\n",
    "        batch_size = 16\n",
    "\n",
    "        checkpoint = ModelCheckpoint('best_model.keras', \n",
    "            verbose=1, \n",
    "            monitor='val_loss',\n",
    "            save_best_only=True, \n",
    "            mode='auto'\n",
    "        ) \n",
    "\n",
    "        self.model.fit(self.x_train, self.y_train, epochs=n_epochs, batch_size=batch_size, validation_data=(self.x_valid, self.y_valid),\n",
    "                       callbacks=[checkpoint])\n",
    "\n",
    "    def calculate_activations(self):\n",
    "\n",
    "        layer_outputs = [layer.output for layer in self.model.layers[:5]]\n",
    "        activation_model = models.Model(inputs=self.model.layers[0].input, outputs=layer_outputs)\n",
    "        self.activations = activation_model.predict(x=self.x_train)\n",
    "\n",
    "    def calculate_artifact_clusters(self):\n",
    "\n",
    "        self.n_clusters_conv_1 = 4\n",
    "        self.n_clusters_conv_2 = 4\n",
    "        self.n_clusters_dense = 4\n",
    "\n",
    "        self.artifact_clusters = pd.DataFrame()\n",
    "\n",
    "        \"\"\" activations_f = self.activations[0][:,:,:,0]\n",
    "        activations_f = activations_f.reshape([activations_f.shape[0],activations_f.shape[1]*activations_f.shape[2]])\n",
    "        print(activations_f)\n",
    "        np.savetxt(\"activations_f.csv\", activations_f, delimiter=\",\") \"\"\"\n",
    "\n",
    "        for f in range(self.n_filters_conv_1):\n",
    "\n",
    "            print('filter: '+str(f))\n",
    "\n",
    "            activations_f = self.activations[0][:,:,:,f]\n",
    "            activations_f = activations_f.reshape([activations_f.shape[0],activations_f.shape[1]*activations_f.shape[2]])\n",
    "            ac_f = AgglomerativeClustering(n_clusters=self.n_clusters_conv_1).fit(activations_f)\n",
    "\n",
    "            self.artifact_clusters['l0_f'+str(f)] = ac_f.labels_\n",
    "\n",
    "        for f in range(self.n_filters_conv_2):\n",
    "\n",
    "            print('filter: '+str(f))\n",
    "\n",
    "            activations_f = self.activations[1][:,:,:,f]\n",
    "            activations_f = activations_f.reshape([activations_f.shape[0],activations_f.shape[1]*activations_f.shape[2]])\n",
    "            ac_f = AgglomerativeClustering(n_clusters=self.n_clusters_conv_2).fit(activations_f) \n",
    "\n",
    "            self.artifact_clusters['l1_f'+str(f)] = ac_f.labels_\n",
    "\n",
    "        activations_d_1 = self.activations[3]\n",
    "        ac_d = AgglomerativeClustering(n_clusters=self.n_clusters_dense).fit(activations_d_1)\n",
    "        self.artifact_clusters['l3'] = ac_d.labels_\n",
    "\n",
    "        predictions = self.model.predict(x=self.x_train)\n",
    "        pred = np.argmax(predictions, axis=1)\n",
    "        self.artifact_clusters['p'] = pred\n",
    "\n",
    "    def get_sequential_information_system(self):\n",
    "\n",
    "        self.sis = pd.DataFrame()\n",
    "        #self.sis['conv1'] = self.artifact_clusters['l0_f'+filter_id]\n",
    "        self.sis['conv1'] = self.artifact_clusters.astype(str).loc[:,['l0_f0', 'l0_f1', 'l0_f2', 'l0_f3']].apply('_'.join, axis=1)\n",
    "        self.sis['conv2'] = self.artifact_clusters.astype(str).loc[:,['l1_f0', 'l1_f1', 'l1_f2', 'l1_f3']].apply('_'.join, axis=1)\n",
    "        self.sis['dense1'] = self.artifact_clusters['l3']\n",
    "        self.sis['output'] = self.artifact_clusters['p']\n",
    "\n",
    "        return self.sis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kp_3_11_10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
